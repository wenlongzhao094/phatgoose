import src.models
import src.models.addons
import src.models.manipulations

M/TEACHER_MODEL/ExposeHidden.reduction_method = None
M/TEACHER_MODEL/ENCODER/ExposeHidden.position = "before"
M/TEACHER_MODEL/DECODER/ExposeHidden.position = "before"

M/TEACHER_MODEL/watch_hiddens:
    prepare_mask_modules = "encoder"
    prepare_mask_addon_name = "prepare_mask"

M/TEACHER_MODEL/ENCODER/watch_hiddens:
    expose_hidden_modules = "encoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"


M/TEACHER_MODEL/DECODER/watch_hiddens:
    expose_hidden_modules = "decoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"

M/TEACHER_MODEL/FFNExperts:
    non_linearity = "identity"
    position = "beside"
    d_in = "host_module.in_features"
    d_out = "host_module.out_features"
    divide_by_d_bottleneck = True
    d_bottleneck = 16

M/TEACHER_MODEL/make_moe:
    expert_class = "ffn"
    router_addon_name = "router"
    expert_addon_name = "expert_lora"

M/TEACHER_MODEL/ENCODER/make_moe:
    expert_modules = "encoder_linear"
    router_modules = "encoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"
    router_addon_name = "router"

M/TEACHER_MODEL/DECODER/make_moe:
    expert_modules = "decoder_linear"
    router_modules = "decoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"
    router_addon_name = "router"

M/TEACHER_MODEL/Router.d_router="host_module.in_features"
