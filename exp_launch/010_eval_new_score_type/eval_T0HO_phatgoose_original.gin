import src.models
import src.models.addons
import src.models.manipulations
import src.procedures
import src.procedures.utils
import src.utils.logging

exp_name = "eval_T0HO_phatgoose_paper"
output_dir = "exp_out/010_eval_new_score_type/eval_T0HO_phatgoose_paper/"

# --- T5-XL Model ---
M/MODEL/hf_torch_model:
    model_class = "seq2seq_lm"
    model_name_or_path = "google/t5-xl-lm-adapt"

M/MODEL/hf_tokenizer:
    model_name_or_path = "google/t5-xl-lm-adapt"

M/MODEL/InterfaceMixin:
    language_modeling_interface = "lm_4encdec"
    generation_interface = "gen_4encdec"
    mutiple_choice_interface = "mc_byppl_4encdec"

M/MODEL/build.cls = @Model
M/MODEL/Model:
    torch_model = @hf_torch_model()
    tokenizer = @hf_tokenizer()
    trainable_params = "all"
    mix_precision = "bf16"


# --- MoE AddOn ---
M/MODEL/ExposeHidden.reduction_method = None
M/MODEL/ENCODER/ExposeHidden.reduction_method = None
M/MODEL/DECODER/ExposeHidden.reduction_method = None
M/MODEL/ENCODER/ExposeHidden.position = "before"
M/MODEL/DECODER/ExposeHidden.position = "before"

M/MODEL/watch_hiddens:
    prepare_mask_modules = "encoder"
    prepare_mask_addon_name = "prepare_mask"
M/MODEL/ENCODER/watch_hiddens:
    expose_hidden_modules = "encoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"
M/MODEL/DECODER/watch_hiddens:
    expose_hidden_modules = "decoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"

M/MODEL/Router:
    d_router = "host_module.in_features"
    score_type = "original"
    scaling_scores = True
    elementwise_affine = False

M/MODEL/FFNExperts:
    non_linearity = "identity"
    position = "beside"
    d_in = "host_module.in_features"
    d_out = "host_module.out_features"
    d_bottleneck = 16
    topk_value = 2
    normalize_topk = True
    divide_by_d_bottleneck = True

M/MODEL/make_moe:
    expert_class = "ffn"
    router_addon_name = "router"
    expert_addon_name = "expert_lora"
M/MODEL/ENCODER/make_moe:
    expert_modules = "encoder_linear"
    router_modules = "encoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"
    router_addon_name = "router"
M/MODEL/DECODER/make_moe:
    expert_modules = "decoder_linear"
    router_modules = "decoder_linear"
    expose_hiddens_addon_name = "pre_expose_hiddens"
    router_addon_name = "router"


# --- Evaluation ---
P/EVALUATE/build.cls = @Evaluator
P/EVALUATE/Evaluator:
    model = "M/MODEL"
    datasets = ["D/P3RTE/EVAL", "D/P3HSWAG/EVAL", "D/P3COPA/EVAL", "D/P3WIC/EVAL", "D/P3WINOGRANDE/EVAL", "D/P3CB/EVAL", "D/P3STORYCLOZE/EVAL", "D/P3ANLI/R1/EVAL", "D/P3ANLI/R2/EVAL", "D/P3ANLI/R3/EVAL", "D/P3WSCFIXED/EVAL"]
    save_results = @save_results
    analysis_processors = [@WriteOutputText(), @RoutingDistribution()]

save_results.save_dir = output_dir
P/EVALUATE/save_results.overwrite = True

WriteOutputText.save_dir = output_dir + "output_text"
RoutingDistribution.save_dir = output_dir + "routing_distribution"
EntropyDistribution.save_dir = output_dir + "entropy_distribution"

M/MODEL/Model.trainable_params = "none"
M/MODEL/load_weights.weight_path = output_dir + "best.pt"
M/MODEL/Model.init_moma_calls = [@M/MODEL/ENCODER/watch_hiddens, @M/MODEL/DECODER/watch_hiddens, @M/MODEL/ENCODER/make_moe, @M/MODEL/DECODER/make_moe, @M/MODEL/load_weights]

main:
    procedure_exec_order = ["P/EVALUATE"]
    exp_name = exp_name
    global_seed = 42
